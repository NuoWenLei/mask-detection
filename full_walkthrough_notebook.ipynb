{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.7.9 64-bit",
   "metadata": {
    "interpreter": {
     "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "source": [
    "# Full Walkthrough"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "## Import Data from Kaggle"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bash\n",
    "export KAGGLE_USERNAME=username\n",
    "export KAGGLE_KEY=key\n",
    "kaggle datasets download -d prithwirajmitra/covid-face-mask-detection-dataset\n",
    "kaggle datasets download -d andrewmvd/face-mask-detection"
   ]
  },
  {
   "source": [
    "## Load and Preprocess Data"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Unzip downloaded zip files and load them into directories\n",
    "\n",
    "import zipfile\n",
    "\n",
    "with zipfile.ZipFile(\"covid-face-mask-detection-dataset.zip\", \"r\") as zipped:\n",
    "    zipped.extractall(\"face-mask-data\")\n",
    "with zipfile.ZipFile(\"face-mask-detection.zip\", \"r\") as zipped:\n",
    "    zipped.extractall(\"face-detection-data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a list of paths to our image data\n",
    "\n",
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "\n",
    "# Instantiate list\n",
    "path_list = []\n",
    "base_path = \"face-mask-data/New Masks Dataset\"\n",
    "\n",
    "# Data was split into 3 modes\n",
    "for mode in [\"Train\", \"Test\", \"Validation\"]:\n",
    "\n",
    "    # Data of each mode is split into mask or no mask\n",
    "    for is_mask in [\"Mask\", \"Non Mask\"]:\n",
    "\n",
    "        # Add all paths in this directory into our path_list\n",
    "        # Each item includes the path to the image and the label if it is masked or not\n",
    "    path_list.extend([[f\"{base_path}/{mode}/{is_mask}/{f}\", [0,1] if is_mask==\"Mask\" else [1,0], mode] \\\n",
    "        for f in listdir(f\"{base_path}/{mode}/{is_mask}\") if isfile(join(f\"{base_path}/{mode}/{is_mask}/{f}\"))])\n",
    "path_list[:5]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip3 install mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "from PIL import Image\n",
    "from mtcnn import MTCNN\n",
    "import numpy as np, pandas as pd\n",
    "import cv2\n",
    "\n",
    "# Define uniform image size\n",
    "image_x = 299\n",
    "image_y = 299\n",
    "\n",
    "\n",
    "def preprocess_image(image, net_h, net_w):\n",
    "    new_h, new_w, _ = image.shape\n",
    "\n",
    "    # determine the new size of the image\n",
    "    if (float(net_w)/new_w) < (float(net_h)/new_h):\n",
    "        new_h = (new_h * net_w)//new_w\n",
    "        new_w = net_w\n",
    "    else:\n",
    "        new_w = (new_w * net_h)//new_h\n",
    "        new_h = net_h\n",
    "    \n",
    "    # Try resizing image, sometimes there are images that trigger errors related to cv2's source code, which we can filter out\n",
    "    try:\n",
    "      resized = cv2.resize(image/255., (int(new_w), int(new_h)))\n",
    "      \n",
    "      # Create gray background with right size\n",
    "      new_image = np.ones((net_h, net_w, 3)) * 0.5\n",
    "\n",
    "      # Overlay resized image on gray background, essentially padding the image to fit the net size\n",
    "      new_image[int((net_h-new_h)//2):int((net_h+new_h)//2), int((net_w-new_w)//2):int((net_w+new_w)//2), :] = resized\n",
    "      new_image = np.expand_dims(new_image, 0)\n",
    "      return new_image\n",
    "    except Exception as e:\n",
    "      print(e)\n",
    "      return\n",
    "\n",
    "def data_parse(files):\n",
    "  data_dict = {}\n",
    "\n",
    "  # Instantiate face detector MTCNN,\n",
    "  # which is a Multi-Task Convolusional Neural Network.\n",
    "  # Learn more at: https://github.com/ipazc/mtcnn\n",
    "  detector = MTCNN()\n",
    "\n",
    "  # Create separat datasets for each mode.\n",
    "  # This allows for us to train, test, and validate our model\n",
    "  # on different sets of data\n",
    "  for mode in ['Test', 'Train', 'Validation']:\n",
    "\n",
    "    # Create the features and label lists for each mode\n",
    "    data_dict[mode] = [[],[]]\n",
    "  \n",
    "  # Loop through each image\n",
    "  for i,f in enumerate(files):\n",
    "\n",
    "    # Counter to show progress\n",
    "    if i % 100 == 0:\n",
    "      print(i)\n",
    "\n",
    "    # Load in image as a 3D array (d1 is y, d2 is x, d3 is RGB)\n",
    "    im = cv2.cvtColor(cv2.imread(f[0]), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "    # Find all faces in image\n",
    "    faces = detector.detect_faces(im)\n",
    "\n",
    "    # Loop through each face\n",
    "    for face in faces:\n",
    "\n",
    "      # Only take the part of the image that is detected to be a face\n",
    "      far_x = face['box'][0]+face['box'][2]\n",
    "      far_y = face['box'][1]+face['box'][3]\n",
    "      im_arr = im[face['box'][1]:far_y, face['box'][0]:far_x, :3]\n",
    "      if 0 in im_arr.shape:\n",
    "        continue\n",
    "      # Pad image to make it a uniform size (299x299) as defined above\n",
    "      process_res = preprocess_image(im_arr, image_y, image_x)\n",
    "      if process_res is not None:\n",
    "\n",
    "        # Append image and label to the appropriate mode\n",
    "        data_dict[f[2]][0].append(process_res)\n",
    "        data_dict[f[2]][1].append(f[1])\n",
    "  return data_dict\n",
    "\n",
    "d = {}\n",
    "\n",
    "# Check if there is an already trained model\n",
    "if not isfile('/content/mask_predictor.h5'):\n",
    "  d = data_parse(path_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_dict = {}\n",
    "if not isfile('/content/mask_predictor.h5'):\n",
    "\n",
    "\n",
    "  # Format to \"X/y_Test/Train/Validation\"\n",
    "  for mode in ['Test', 'Train', 'Validation']:\n",
    "    final_dict[f\"X_{mode}\"] = np.array(d[mode][0])[:, 0, :, :, :]\n",
    "    final_dict[f\"y_{mode}\"] = np.array(d[mode][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "if not isfile('/content/mask_predictor.h5'):\n",
    "\n",
    "  # First X_Train image\n",
    "  plt.imshow(final_dict['X_Train'][0])\n",
    "  plt.show()"
   ]
  },
  {
   "source": [
    "## Model Definition with Transfer Learning Base Model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import Xception\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use Xception Model as a base model\n",
    "base_model = Xception(include_top=False, input_shape=(image_x, image_y,3))\n",
    "\n",
    "# Freeze weights of Xception because Xception is already really good at identifying images\n",
    "base_model.trainable = False\n",
    "\n",
    "# Create Sequential model based on Xception\n",
    "model = Sequential([\n",
    "                    # Xception\n",
    "                    base_model,\n",
    "\n",
    "                    # Turn 2D to 1D\n",
    "                    Flatten(),\n",
    "\n",
    "                    # 2 units correspond to mask% and no_mask%\n",
    "                    Dense(2, activation='sigmoid')\n",
    "])\n",
    "\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='binary_crossentropy', # Binary_crossentropy because we are doing binary classification\n",
    "    optimizer='adam', # Adam is a generally strong optimizer for image processing\n",
    "    metrics=[tf.keras.metrics.BinaryAccuracy()] # Measure success with binary accuracy\n",
    ")\n",
    "\n",
    "model.summary()"
   ]
  },
  {
   "source": [
    "## Model Training"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define some necessary parameters\n",
    "EPOCHS = 3 # How many rounds of training we want to do\n",
    "BATCH_SIZE = 32 # The size of one batch of data\n",
    "\n",
    "if isfile('/content/mask_predictor.h5'):\n",
    "  # Load model from file if file exists\n",
    "  model = keras.models.load_model('/content/mask_predictor.h5')\n",
    "else:\n",
    "  # Train model with .fit() method\n",
    "  model.fit(final_dict[\"X_Train\"], final_dict['y_Train'], validation_data=(final_dict[\"X_Validation\"], final_dict[\"y_Validation\"]), epochs=EPOCHS, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "source": [
    "## Model Evaluation"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate model success with .evaluate() method\n",
    "loss, acc = model.evaluate(final_dict[\"X_Test\"], final_dict[\"y_Test\"], batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show Loss and Accuracy\n",
    "print(f\"LOSS {loss}\")\n",
    "print(f\"ACCURACY : {acc}\")"
   ]
  },
  {
   "source": [
    "## Create Prediction Serving Preprocessing Functions"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_serving(f):\n",
    "\n",
    "  # Instantiate image list\n",
    "  X = []\n",
    "  \n",
    "\n",
    "  # Instantiate MTCNN detector\n",
    "  # Learn more at: https://github.com/ipazc/mtcnn\n",
    "  detector = MTCNN()\n",
    "\n",
    "  # # Loop through each provided file path\n",
    "  # for f in files:\n",
    "\n",
    "  # Read image as 2D numpy array\n",
    "  im = cv2.cvtColor(cv2.imread(f), cv2.COLOR_BGR2RGB)\n",
    "\n",
    "  # Detect faces in image\n",
    "  faces = detector.detect_faces(im)\n",
    "  if len(faces) == 0:\n",
    "    print(f\"File {f} Contains No Faces\")\n",
    "    return\n",
    "\n",
    "  # Loop through each face\n",
    "  for face in faces:\n",
    "\n",
    "    # Crop image to contain one face\n",
    "    far_x = face['box'][2] + face['box'][0]\n",
    "    far_y = face['box'][3] + face['box'][1]\n",
    "    im_arr = im[face['box'][1]:far_y, face['box'][0]:far_x, :3]\n",
    "    if 0 in im_arr.shape:\n",
    "      print(\"Invalid Face, Please Try Another Image\")\n",
    "      return\n",
    "\n",
    "    # Pad image to fit correct size\n",
    "    process_res = preprocess_image(im_arr, image_y, image_x)\n",
    "    if process_res is None:\n",
    "      print(\"Invalid Face, Please Try Another Image\")\n",
    "      return\n",
    "\n",
    "    X.append(process_res)\n",
    "  return np.array(X), faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image, ImageDraw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Draw face boxes on image to identify mask or not\n",
    "def draw_faces(f, boxes, preds, confidence=1):\n",
    "  im = Image.open(f)\n",
    "  imDraw = ImageDraw.Draw(im)\n",
    "  for i, box in enumerate(boxes):\n",
    "    color = \"green\" if preds[i][0] else \"red\"\n",
    "    imDraw.rectangle([(box[0], box[1]), (box[0]+box[2], box[1]+box[3])], outline=color)\n",
    "    if confidence:\n",
    "      imDraw.rectangle([(box[0], box[1]), (box[0]+120, box[1]-20)], fill=color)\n",
    "      imDraw.text([box[0]+2, box[1]-15], f\"Confidence: {preds[i][1]:.2f}\", fill=\"white\")\n",
    "\n",
    "  return im"
   ]
  },
  {
   "source": [
    "## Establishing Pipeline"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "source": [
    "### Steps:\n",
    "###   - get path to image\n",
    "###   - preprocess image with serving_parse()\n",
    "###   - predict all returned data with model"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Time the entire operation\n",
    "start_time = time.time()\n",
    "\n",
    "# Get path to image\n",
    "given_path = \"/content/test_image3.jpg\"\n",
    "\n",
    "# Preprocess image with data_parse() and get all faces in image\n",
    "data, faces = preprocess_serving(given_path)\n",
    "\n",
    "# Reshape data for prediction convenience\n",
    "data= data.reshape(data.shape[0], image_y, image_x, 3)\n",
    "\n",
    "# Predict data with model\n",
    "pred_prob = model.predict(data)\n",
    "\n",
    "# Do basic response and create binary prediction list\n",
    "preds = []\n",
    "for prob in pred_prob:\n",
    "  pred = np.argmax(prob)\n",
    "  preds.append([pred, prob[pred]])\n",
    "  if pred:\n",
    "    print(\"You are wearing a mask\")\n",
    "  else:\n",
    "    print(\"You are not wearing a mask\")\n",
    "print(f\"Time of Image Detection and Prediction: {time.time()-start_time:.2f}\")\n",
    "second_time = time.time()\n",
    "\n",
    "# Draw bounding boxes of faces on image\n",
    "im_check = draw_faces(given_path, [i['box'] for i in faces], preds, confidence=1)\n",
    "\n",
    "\n",
    "display(im_check)\n",
    "\n",
    "third_time = time.time()\n",
    "print(f\"Time of Image Drawing: {third_time-second_time:.2f}\")"
   ]
  }
 ]
}